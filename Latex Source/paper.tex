\documentclass[manuscript, screen, review]{acmart} %removing review removes the numbers on left side

% part of the template 
\AtBeginDocument{%
  \providecommand\BibTeX{{%  
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}} %chktex 1

% part of the template 
\setcopyright{acmcopyright}
\copyrightyear{2024}
\acmYear{2024}
\acmDOI{XXXXXXX.XXXXXXX}

% packages that I added
\usepackage{graphicx} %% For pictures
\graphicspath{{./pics/}}

\begin{document}

\title{Music Versus No Music Effectiveness On Cognitive Response Time and Typing Efficiency}

\author{Jonquill Howlett}
\email{jonquill.howlett@colostate.edu}
\affiliation{%
  \institution{Colorado State University}
  \city{Berthoud}
  \state{Colorado}
  \country{USA}
  \postcode{80513-0650} %chktex 8
}

\author{Shea Spalding}
\email{Shea1@colostate.edu}
\affiliation{%
  \institution{Colorado State University}
  \city{Fort Collins}
  \state{Colorado}
  \country{USA}
  \postcode{80521-1873} %chktex 8
}

\renewcommand{\shortauthors}{Howlett, Spalding}
% the template does not show any shortauthors

\begin{abstract}
A two-part test was conducted to determine if there was a correlation between the effectivness of music versus no music on cognitive response time
and typing efficiency. A participant would take a typing test and quantified behavioral test (QBTest) with three conditions.
The condiditons would be instrumental music (music with no lyrics), lyrical music (music with lyrics), and lastly no music. While the participant takes the QBTest, the EyeWriter 2.0,
a type of eye tracker, will track the participants eye movements.
Individually the two test were not statistically significant. The typing test's \textit{p} value was 0.1172 whereas the QBTest's \textit{p} value was 0.0818 when ran through ANOVA. There was correlation between the effectiveness of the two on response time. This 
can be seen in a heat map of eye movements that is generated from the EyeWriter when inputted into GISPro, a program that analyses geographic information systems which a heatmap is considered.

\end{abstract}

\ccsdesc{Music, Typing Efficiency, Cognitive Function}
\keywords{Typing Efficiency with Music, Cognitive Function, Quantified Behavioral Test}
\maketitle

\section{Introduction}
This project will focus on people's ability to type with distractions such as different types of music playing. 
It will then test their cognitive ability to focus on a hand/eye coordination test in which we will test how well they can match shapes by measuring speed and accuracy. 
The two-part test aims to help test if the music is too distracting or will help the people be more efficient at their work. 
This is important because many people do their homework or jobs while listening to music and should they make a mistake, it could end up costing someone their grade or the mistake at work has a cascading effect to cause more errors. 
According to the arousal-mood hypothesis, changes in arousal and mood when exposed to auditory stimulation can influence cognitive function~\cite{Chee}.
The two-part test will help determine if there is a correlation between the effectiveness of music versus no music on cognitive response time and typing efficiency. 

\subsection{Eye Tracking}
Eye tracking technology, such as the EyeWriter 2.0, has become increasingly valuable in cognitive research, allowing for precise measurement and analysis of visual attention and eye movements~\cite{Rana8642988}. 
In this study, we incorporate the EyeWriter 2.0 to track participants' eye movements during the QBTest, a hand-eye coordination task.
The EyeWriter 2.0 offers high-resolution tracking, accurately capturing gaze patterns and fixations.
As Chen~\cite{Chen23876} points out while exploring the relationships between distractibility and Eye Tracking during online learning assessments they found significant differences between more distractions meant more distracted eyes. We believe by analyzing participants' eye movements during the QBTest under different music conditions, we aim to understand how distractions, such as music, influence visual attention and cognitive performance.
Understanding the impact of music on cognitive response time and typing efficiency, as measured by the QBTest and eye tracking, can provide valuable insights for improving work and study environments where music is commonly used as a background stimulus.

\subsection{QBTest}
The Quantified Behavioral Test (QBTest) is a well-established tool for assessing cognitive function, particularly in measuring hand-eye coordination, speed, and accuracy. 
It is usually used to diagnose ADHD in adults and children as mentioned by~\cite{Stevanovic} Stevanovic in their study of 'The Structure and Diagnostic Accuracy of the QbTest in Pediatric ADHD.
Developed as a standardized measure, the QBTest provides valuable insights into cognitive performance across different tasks and conditions.
In this study, the QBTest serves as a central component for evaluating participants' cognitive response time and typing efficiency under various music conditions.
By administering the QBTest alongside eye tracking using EyeWriter 2.0, we aim to understand the impact of music on cognitive function and task performance.
The QBTest's ability to quantify cognitive performance makes it an ideal tool for this study, allowing us to measure the effects of music on participants' ability to focus, process information, and perform tasks fairly accurately. 
It is also important to understand that it is not completely accurate as discussed by Hult~\cite{Hult}.
Through this research, we seek to provide insights that can enhance our understanding of how environmental factors, such as music, influence cognitive processes.

\subsection{Typing Test}
Typing proficiency is a fundamental skill in today's digital age, essential for academic and professional success. 
However, various factors can influence typing efficiency, including environmental stimuli such as music Silverberg~\cite{AudioDistractionsAshley} found that the results of their typing test showed that although there was a significant difference in the times between paragraphs, there were no significant differences in typing speed between the audio distractions being played. 
Understanding how music affects typing speed and accuracy is crucial for optimizing work and study environments.
This study uses a typing test to assess participants' typing performance under different music conditions. 
The test presents participants with lyrics from popular songs, simulating a real-world typing scenario where individuals may listen to music while working or studying.
By measuring typing speed and accuracy under conditions of music with lyrics, music without lyrics, and no music (silent condition), we aim to determine the impact of music on typing efficiency. 
This research will contribute to our understanding of how environmental factors, such as music, can affect cognitive processes related to typing and may have practical implications for improving productivity in various settings.

\section{Related Works}
\subsection{Music While Working}  % if we don't add anything to \subsection{Eye Tracking and Quantified Behavioral Test} we need to remove this subsection
While there is not necessarily a concrete answer for whether music or background noise is effective on cognitive function, there have been many
studies that attempt to determine the answer. 
The other studies attempted to search for this answer by focusing on word processing on a computer with the background music and the user's ability to formulate sentences~\cite{ransdell2001141}, or determining if background music helps users to keep their attention on their task at hand~\cite{kiss2021effect}. 
Similar to Kiss and Linnell~\cite{kiss2021effect}, Mathew ~\cite{mathew2022inherently} also examined how motivation and music were used hand-in-hand on ``a time-consuming task and task performance''. 
A different study done in 2010 again found similar results of music both being a hindrance and benefit~\cite{AudioDistractionsAshley}. 
According to Gonzalez and Aiello~\cite{Gonzalez_Aiello_2019}, the degree of cognitive function may be based on an individual's personality. 
Furnham et al., also determined this was based on personality in a study done between extraverts and introverts although ``no significant interactions were found''~\cite{distractingEffectsFurnham}.

The research done by Komlao found that music or background music was again based on an individual's personality but that music, even music that the participants were familiar with, were a distraction and ``was found to negatively impact task performace'' overall~\cite{komlao2018variations}.
This was contrary to the previous studies found by Komlao where the ``music could help increase productivity for simple, monotonouse tasks''~\cite{komlao2018variations}.

Although Ransdell and Gilroy~\cite{ransdell2001141} suggests that the music is a detriment, those with ``musical training and high working memory span wrote better essays with longer sentences''. 
This suggests that while the music slowed down the participants, it did not necessarily lower their cognitive ability in typing on their computer while focusing on forming text for the written essay for this particular study. 
For Silverberg~\cite{AudioDistractionsAshley}, the music caused enough of a difference in the time that was taken for writing a paragraph but ``there were no significant differences in typing speed between the audio distractions''. 
This again may suggest that the participant's cognitive ability was not hindered when typing and may transfer directly after should the participants have taken a test measuring their cognitive function. 
The slow timing was again seen by Gonzalez and Aiello~\cite{Gonzalez_Aiello_2019} in which ``music generally impaired performance on a complex task but improved performance on a simple task''. 

The study done through Kiss and Linnell~\cite{kiss2021effect} saw opposite results as to Gonzalez and Aiello~\cite{Gonzalez_Aiello_2019}. The music or background noise ``enhanced'' the reaction time and performance of the tasks that are given to be completed. 
The results from Mathew~\cite{mathew2022inherently} were split. 
The music was a detriment for logic puzzles in the user's accuracy but aided in the efficiency of a writing task. 
According to Bramwell-Dicks et al., the instrumental music used in their study had better results on typists in speed and accuracy whereas music with vocals, the participants fared worse~\cite{bramwell2016can}.
While only a quasi-experiment, Oldham et al., found that personal headphones and Walkmans for employees had a positive correlation if the job complexity was not complex but also that employee satisfaction at this company was higher if they were allowed to use their walkman while working~\cite{oldhamListen}. Dobbs et al., also found the correlation that while music produced lower scores than silence it was better than just ``noise''~\cite{effectsOfBackgroundDobbs}.
Further research by \cite{gupta2023effect}Gupta et al. (2023) explored the effects of different music genres on attention and memory during cognitive tasks, providing valuable insights into how musical characteristics influence cognitive performance. Similarly, Sharma et al. \cite{sharma2022impact}(2022) conducted a study examining the impact of various types of music on productivity and task performance, shedding light on the differential effects of instrumental and lyrical music on cognitive function.

\subsection{Eye Tracking}
In addition to the aforementioned studies, an innovative approach to eye-tracking technology was presented by \cite{Malaikar2018Arduino}Malaikar et al. (2018) in their work titled "Arduino Based Eye-Writer Using PS3 Eye Camera." This research introduced an eye-tracking device and custom software, known as the Eye-Writer, which aimed to aid individuals with neuromuscular disorders and injuries in drawing or writing using only their eye movements. The Eye-Writer utilized an Arduino platform and a PS3 Eye Camera to track the movement of the user's eyes, enabling creative expression without the need for physical mobility. This novel application of eye-tracking technology showcases the diverse range of potential applications in assistive technology and human-computer interaction.

\section{Methodology}
\subsection[short]{Equipment} 
Participants used two different MacBook Pros in this study due to the nature of the eye tracker setup although both were running on Sonoma or MacOS 14. One MacBook Pro was used to administer the QBTest, and it had the eye tracker mounted on it. The positioning of the eye tracker made it challenging to use this MacBook Pro for the typing test and QBTest. 
Participants used the MacBook Pro with the eye tracker for the QBTest to ensure that the eye tracker could accurately track their eye movements during the test. 
A Bluetooth keyboard allowed participants to press the space bar in the Quantified Behavioral test easily as the mounting of the eye tracker made it harder to access
the space bar on the MacBook.
Using two separate MacBook Pros allowed for the independent administration of the QBTest and typing test, ensuring that participants could perform each task without any physical hindrance from the eye tracker.

\subsubsection{EyeWriter 2.0}
The IR camera captures the eye movements of the participant.
It is mounted on the laptop that participants use for the QBTest, allowing for the tracking of eye movements during the test.
IR LEDs are used to illuminate the eye to enhance the visibility of the eye for tracking purposes. 
These LEDs are also mounted on the laptop along with the IR camera. 
The mounting system holds the IR camera and IR LEDs in place relative to the participant's eye. 
It ensures that the camera has a clear view of the eye for accurate tracking. 
Cables are used to connect the IR camera and IR LEDs to the laptop. These cables transmit data and power between the components.
An Arduino microcontroller allowed the computer to communicate with the camera, infrared LED lights, and computer.

\subsubsection{Typing Test}
The typing program was written in Python and compiled using Python3.9. 
While python can run on any device that has python installed, this study only used the two Macbook Pros. 
The singularity of the devices was used as the center of the screen for the typing test was hard coded when setting the starting position of the window for the typing test. 

\subsubsection{Quantified Behavioral Test}
The Quantified Behavioral Test program was written in Python and compiled using Python3.9.
The package pygame was used for this interface compared to the package tkinter used for the typing test.
The Bluetooth keyboard allowed the participant to hit the space bar when the QBTest said to hit the space bar.

\subsection[short]{Procedure}
Each participant was instructed to read and then sign the consent form. While the consent form had the basis of what they would be doing, they were given more detail as to the instructions when they were ready to begin.
The two computers were set up side by side so that it would be easy for the participant to switch between the typing test and QBTest.
This setup also made it simple for the music component as the participants did each level together 
(e.g. typing test then QBTest without having to change the music or swapping to no music)
before moving on to the next level. 
Because of the way that the heatmap was coded, we had to make sure that each level was done in the same order for all the participants.
We made sure to always do instrumental music, lyrical music, and then no music. 

\subsection[short]{Participants}
Twelve participants were recruited from Colorado State University or Fort Collins, Colorado. Two males and eight females all in the age range of 18-23. There were no restrictions in regards to their major as long as they were able to type on a keyboard with no tilt on the keys.
They have all previously either learned to type at primary school or through necessity.

\subsection[short]{Design}

\begin{figure}
  \includegraphics[width=0.5\textwidth]{typingTest}
  \caption{Images of what the user will see in the typing test}
  \Description{Images of what the user will see in the typing test}
  \label{typingTest}
\end{figure}

After obtaining consent from all participants, they proceeded to take the typing test. The test presented lyrics from popular songs within a graphical user interface (GUI). 
The interface automatically calculated typing accuracy and the time the attempt took in the program's backend, allowing participants to focus solely on completing the test.
Each participant completed the typing test under three conditions: music with lyrics, music without lyrics, and no music (silent condition).
Multiple levels of music intensity were utilized within each condition to assess varying degrees of distraction.
The GUI of the typing test was built with simplicity in mind. The starting window was pulled up so as not to confuse participants with the code as seen in Figure~\ref{typingTest}a. The participants saw Figure~\ref{typingTest}b while the test was running, while Figure~\ref{typingTest}c was the signifier that the typing portion was finished. 

They were given the instructions in the GUI with the text area where their text is clearly visible and the only button in the window to start the test and timer. 
After they hit the ``Get the Typing Test'' button, the lyrics of the randomly selected songs were displayed for the user to type. 
The text box for the users was already in focus with a ``Done'' button. After the users hit ``Done'', their accuracy and speed were presented.

\begin{figure}
  \center
  \includegraphics[width=0.5\textwidth]{eyetracker_setup.png}
  \caption{EyeWriter 2.0 Setup}
  \Description{Image of the eye tracker setup}
  \label{EyeWriter}
\end{figure}

Following the typing test, participants proceeded to the cognitive task component of the study, which was also conducted under the three aforementioned conditions. 
While the participants did the cognitive task of a quantified behavioral test, their eye movement will be tracked by the EyeWriter 2.0 camera that we specially built for this study. 
The EyeWriter 2.0 system consists of a camera mounted on the participant's laptop, which tracks eye movements and allows for precise measurement of gaze direction and fixation duration. This can be seen in Figure~\ref{EyeWriter}.

Participants were seated in a comfortable position facing the laptop screen.
The laptop is placed on top of a laptop stand while the eye tracker is mounted on a wooden frame. 
While the eye tracker is on a moveable slider, it is centered in front of the screen. 
At the ends of the wooden frame are infrared lights that flash at sixty frames per second. % WILL NEED TO VERIFY THAT IT IS 60 FPS
Although not pictured, a Bluetooth keyboard is used by the participant for the quantified behavioral test (QBTest).

\begin{figure}
  \includegraphics[width=0.5\textwidth]{qbTest.png}
  \caption{Images of what the user will see in the QBTest}
  \Description{Images of what the user will see in the QBTest}
  \label{QBTest}
\end{figure}

During the cognitive task component of the study, participants performed a Quantified Behavioral test or QBTest while their eye movements were tracked by the EyeWriter 2.0.
The QBTest is a computerized test designed to assess various aspects of cognitive function, including attention, impulsivity, and response control.
The user will then see Figure~\ref{QBTest}. Figure~\ref{QBTest}a is the screen that will be displayed before the participant is ready to begin the QBTest.
Figure~\ref{QBTest}b is what the user will see during the test. Figure~\ref{QBTest}b also displays what the user will see when they are correct and incorrect.
Figure~\ref{QBTest}c displays for only a few seconds but shows the user their score.
The Quantified Behavioral test (QBTest) employed in this study is a computerized assessment tool designed to evaluate multiple facets of cognitive function, including attention, impulsivity, and response control. Developed specifically for this research, the QBTest presents participants with a series of tasks and stimuli designed to elicit cognitive responses while their eye movements are simultaneously tracked by the EyeWriter 2.0.

During the cognitive task component of the study, participants engage with the QBTest while their eye movements are monitored in real time. Figure~\ref{QBTest} illustrates the interface and feedback provided during the QBTest. Figure~\ref{QBTest}a depicts the initial screen displayed to participants before commencing the test, indicating readiness to begin. Once initiated, Figure~\ref{QBTest}b illustrates the interface presented to participants during the test, providing visual cues and prompts for task completion. Additionally, feedback for correct and incorrect responses is displayed to the user, facilitating real-time performance monitoring.

Furthermore, Figure~\ref{QBTest}c showcases the summary screen presented to participants after the two-minute testing period, displaying their overall score. This feedback mechanism enables participants to track their performance and provides researchers with quantitative data regarding cognitive function and task performance.

The QBTest serves as a valuable component of this study, allowing for assessing cognitive abilities in conjunction with eye-tracking data, thereby offering insights into the interplay between cognitive processes and ocular behaviors in individuals utilizing assistive technologies such as the EyeWriter 2.0.

\section{Results and Discussion}
Within-subjects testing was used for our ten participants. Individually, the typing test and QBTest scores were not statistically significant. However, the ANOVA conducted on the heatmap data obtained with the eyetracker revealed statistically significant results.

Interestingly, we observed that eye darting occurred most frequently in conditions with no music and music with lyrics. In contrast, the heatmap generated during music without lyrics showed a higher concentration of eye movements. This suggests that different auditory stimuli may influence participants' eye movements differently.

The increased occurrence of eye darting in conditions without music could indicate heightened visual scanning behavior, possibly due to reduced auditory distraction. Conversely, in conditions with music and lyrics, participants might experience a cognitive load associated with processing both auditory and visual information, leading to more frequent eye darting as they attempt to manage multiple stimuli.

On the other hand, the higher concentration observed in the heatmap for music without lyrics could imply focused attention or reduced visual distraction in response to the auditory stimulus. This finding aligns with research suggesting that instrumental music, devoid of lyrical content, may enhance concentration and cognitive performance by providing a soothing yet stimulating background.

These observations underscore the complex interplay between auditory stimuli and visual attention, highlighting the need for further investigation into how different types of music impact eye movements and cognitive processes.


\begin{figure}
  \includegraphics[width=0.3\textwidth]{time}
  \caption{Time (s) of participants for typing test}
  \Description{Bar graph for participants in seconds}
  \label{timeL}
\end{figure}

While not statistically significant, the \textit{p} value for time was 0.1172 whereas the \textit{p} value for accuracy was 0.2334.
The bar graph in Figure~\ref{timeL} for the time in seconds for the typing test was quite telling. The condition for no music was consistently faster than both
lyrical music and instrumental music. The typing tests unfortunately did not record which typing test of the five that each participant did so we
were unable to compare each test against another participant with the same test.

\section{Conclusion and Future Works}
In conclusion, our study investigated the influence of auditory stimuli on eye movements using an eyetracking device. While the typing test results were not statistically significant, our analysis of the heatmap data revealed intriguing patterns in participants' eye movements under different auditory conditions. Specifically, we observed that eye darting occurred most frequently in conditions with no music (Figure \ref{fig:no-music}) and music with lyrics (Figure \ref{fig:music-lyrics}), while music without lyrics (Figure \ref{fig:music-no-lyrics}) led to a higher concentration of eye movements.
Looking ahead, there are several avenues for future research and improvements. Firstly, it would be beneficial to incorporate a recording of the specific typing test completed by each participant, as we suspect that familiarity with certain song lyrics may have influenced typing performance. Additionally, expanding the length and diversity of text in the typing test could provide further insights into how different stimuli affect typing accuracy and speed. Experimenting with a broader range of auditory stimuli, including older songs or entirely different texts, could help elucidate the factors influencing participants' eye movements.
Furthermore, exploring the cognitive mechanisms underlying the observed eye movement patterns and their relationship with auditory processing could enhance our understanding of multimodal perception and attention. Investigating individual differences in response to auditory stimuli, such as musical preferences or language proficiency, could also offer valuable insights into the variability of eye movement behavior across diverse populations.
In summary, our findings contribute to the growing body of research on the interplay between auditory stimuli and visual attention, highlighting the need for continued exploration and refinement of experimental methodologies to uncover the underlying mechanisms. By addressing these avenues for future research, we can further advance our understanding of human perception and enhance the design of technologies aimed at optimizing cognitive performance in various contexts.

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{1.png}
    \caption{Music with no Lyrics}
    \label{fig:enter-label}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{Music with Lyrics.png}
    \caption{Music with Lyrics}
    \label{fig:enter-label}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{3.png}
    \caption{No Music}
    \label{fig:enter-label}
\end{figure}


\bibliographystyle{ACM-Reference-Format}
\bibliography{paper}

\end{document}
